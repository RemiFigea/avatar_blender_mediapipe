# avatar_blender_mediapipe

Welcome to the **avatar_blender_mediapipe** repository!

The aim of this repository is to generate a Blender animation of a human character reproducing the movement of a real person in a video by using landmarks extracted with Mediapipe.

This repository is not finished yet, and there is still a lot to do and improve!

For now, you can take a glance at the results with specific landmark files if you have Blender installed on your computer.

This project generates results using data files prepared in the /data folder. The main script, blender_script.py, depends on these files. The scripts used to prepare these files are in the /scripts folder. They are not necessary to run the main script.


## Main challenges

Challenges are various. Here are some relevant ones:

- One challenge is to find a solution to adapt landmark coordinates generated by Mediapipe to the various coordinate systems in a scene for a character modeled in Blender.
- Another challenge is to make use of Blender's object properties to generate a 3D model character.

## Repository Structure

The repository is structured as follows:
```
/avatar_blender_mediapipe/
   docker_image/
      src/
         data/
            - original_model.blend
            - test_landmarks_files.json
            /textures/
               - face_skin.png
               - mona2_Packed0_Diffuse.png
               - mona2_Packed0_Gloss.png
               - mona2_Packed0_Specular.png
         static/
         templates/
            - animation.html
         - app.py
         - blender_script.py
      - Dockerfile
      - requirements.txt
   /scripts/
      - create_original_face_mesh.py
      - display_landmarks.py
      - generate_landmarks.py
      - requirements_scripts.txt
    - README.md
```

- **`/docker_image`**: Directory containing the Docker image of the Flask application
- **`/data/`**: Directory containing the data loaded in the script `blender_script.py`.
- **`/test_landmarks_files.json`**: JSON files of Mediapipe landmarks I have extracted from a video to test the script.
- **`/original_model.blend`**: Blender files containing the prepared 3D model character to animate.
- **`/textures/`**: Directory containing PNG images used to create texture of the 3D model character.
- **`/static/`**: Folder used to store the MP4 video file generated by the application.
- **`/templates/`**: Directory containing the templates used by the application
- **`app.py`**: Main script of the Flask application
- **`blender_script.py`**: Script executed by the application to run Blender and generate the animation.
- **`/scripts/`**: Directory containing utility scripts used to prepare the data files.
- **`create_original_face_mesh.py`**: Script to create the face of the original 3D model character that will be use for the animation.
- Note: The character model used is based on the predefined "Mona" model from BlenderKit. I suppress the orginal armature to create an armature adapted to Mediapipe keypoints. I also removed the original face mesh and create one adapted to Mediapipe keypoints.
- **`display_landmarks.py`**:  Script to display the original video with the landmarks drawn on it, to check the landmarks JSON file.
- **`generate_landmarks.py`**:  Script to extract and save the landmarks from a video into a JSON file.
- **`requirements_scripts.txt`** Dependencies required for the utility scripts.


## Getting Started


You need to have Blender installed on your computer.

I worked on a windows computer with Blender 4.2. 

To run the main script, make sure the files in the /data folder are present, and then simply execute:


1. **Clone the Repository:**
   ```bash
   git clone https://github.com/your-username//avatar_blender_mediapipe.git
   
2. **Navigate to the Project Folder:**
   ```bash
   cd /avatar_blender_mediapipe

3. **Set Up the Environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   pip install -r requirements.txt
  
4. **Generate the animation:**
   ```
   - Open Blender on your computer.
   - Load the script 'blender_script.py' in the Text Editor.
   - Run the script.
   ```
   *The animation will be generated with the default landmarks of the files 'test_landmarks_files.json'.*

   ```
   - Open the animation window.
   ```

   *You can now run the animation using the Timeline.*
   
## Contributing

Feel free to contribute to the projects by opening issues or submitting pull requests.

If you have suggestions or improvements, I welcome your feedback!

## License

This repository is licensed under the MIT License. See the LICENSE file for more details.

